import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, confusion_matrix

# --- Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="Steel Plates Faults Classifier", layout="wide")

st.title("ğŸš€ Ù†Ø¸Ø§Ù… ØªØµÙ†ÙŠÙ Ø¹ÙŠÙˆØ¨ Ø§Ù„Ø£Ù„ÙˆØ§Ø­ Ø§Ù„ÙÙˆÙ„Ø§Ø°ÙŠØ©")
st.markdown("""
Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙŠÙ‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„ ÙˆØªØµÙ†ÙŠÙ Ø§Ù„Ø¹ÙŠÙˆØ¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„ÙÙŠØ²ÙŠØ§Ø¦ÙŠØ©ØŒ Ù…Ø¹ Ø¥Ø¸Ù‡Ø§Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ø­ØªÙ…Ø§Ù„ÙŠ Ù„ÙƒÙ„ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø¹ÙŠÙˆØ¨.
""")

# --- 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
@st.cache_data 
def load_data():
    URL_PATH = "https://archive.ics.uci.edu/ml/machine-learning-databases/00198/Faults.NNA"
    features = [
        'X_Minimum', 'X_Maximum', 'Y_Minimum', 'Y_Maximum', 'Pixels_Areas',
        'X_Perimeter', 'Y_Perimeter', 'Sum_of_Luminosity', 'Minimum_of_Luminosity',
        'Maximum_of_Luminosity', 'Length_of_Conveyer', 'TypeOfSteel_A300',
        'TypeOfSteel_A400', 'Steel_Plate_Thickness', 'Edges_Index',
        'Empty_Index', 'Square_Index', 'Outside_X_Index', 'Edges_X_Index',
        'Edges_Y_Index', 'Outside_Global_Index', 'LogOfAreas', 'Log_X_Index',
        'Log_Y_Index', 'Orientation_Index', 'Luminosity_Index', 'SigmoidOfAreas'
    ]
    faults = ['Pastry', 'Z_Scratch', 'K_Scratch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']
    df = pd.read_csv(URL_PATH, sep=r"\s+", header=None)
    df.columns = features + faults
    return df, features, faults

df, features, faults = load_data()

# --- 2. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ---
y_multi = df[faults]
y = y_multi.idxmax(axis=1)
le = LabelEncoder()
y_encoded = le.fit_transform(y)
X = df[features]

# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)

# ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø§Ø³ØªØ®Ø¯Ø§Ù… balanced Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ù…Ø´ÙƒÙ„Ø© Other_Faults)
@st.cache_resource
def train_model(X_t, y_t):
    model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
    model.fit(X_t, y_t)
    return model

model = train_model(X_train, y_train)

# --- 3. Ù‚Ø³Ù… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠ (Live Prediction) ---
st.divider()
st.subheader("ğŸ”® Ø§Ù„ØªÙ†Ø¨Ø¤ ÙˆØªØ­Ù„ÙŠÙ„ Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©")
st.write("Ø£Ø¯Ø®Ù„ Ù‚ÙŠÙ… Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø£Ø¯Ù†Ø§Ù‡ Ù„Ø±Ø¤ÙŠØ© ÙƒÙŠÙ ÙŠÙˆØ²Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ø­ØªÙ…Ø§Ù„ÙŠØ© Ø§Ù„Ø®Ø·Ø£ Ø¹Ù„Ù‰ ÙƒÙ„ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹:")

# Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ù‡Ù… 5 Ù…ÙŠØ²Ø§Øª
feat_importances = pd.Series(model.feature_importances_, index=features)
top_5_features = feat_importances.nlargest(5).index.tolist()

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
input_data = {}
cols = st.columns(len(top_5_features))
for i, feat in enumerate(top_5_features):
    val = cols[i].number_input(f"{feat}", value=float(df[feat].mean()))
    input_data[feat] = val

# Ù…Ù„Ø¡ Ø¨Ù‚ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø¨Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ØªÙˆØ³Ø·Ø©
for feat in features:
    if feat not in input_data:
        input_data[feat] = df[feat].mean()

if st.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹ÙŠÙ†Ø© ÙˆØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª"):
    input_df = pd.DataFrame([input_data])[features]
    
    # Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ù†ÙˆØ¹
    prediction = model.predict(input_df)
    res = le.inverse_transform(prediction)[0]
    
    # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ù„ÙƒÙ„ Ø§Ù„ÙØ¦Ø§Øª
    probs = model.predict_proba(input_df)[0]
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    st.success(f"Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹: **{res}**")
    
    # Ø¥Ù†Ø´Ø§Ø¡ DataFrame Ù„Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ù„Ø¹Ø±Ø¶Ù‡Ø§
    prob_df = pd.DataFrame({
        'Ù†ÙˆØ¹ Ø§Ù„Ø¹ÙŠØ¨': le.classes_,
        'Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø© (%)': probs * 100
    }).sort_values(by='Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø© (%)', ascending=False)

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¹Ø±Ø¶ Ù„Ù†ØªØ§Ø¦Ø¬ Ù†ØµÙŠØ© ÙˆØ±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ
    col_res1, col_res2 = st.columns([1, 2])
    
    with col_res1:
        st.write("ğŸ“‹ **ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù†Ø³Ø¨:**")
        st.dataframe(prob_df.style.format({'Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø© (%)': '{:.2f}%'}))
        
    with col_res2:
        st.write("ğŸ“Š **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª:**")
        fig_prob, ax_prob = plt.subplots()
        colors = ['red' if x == res else 'skyblue' for x in prob_df['Ù†ÙˆØ¹ Ø§Ù„Ø¹ÙŠØ¨']]
        sns.barplot(x='Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø© (%)', y='Ù†ÙˆØ¹ Ø§Ù„Ø¹ÙŠØ¨', data=prob_df, palette=colors, ax=ax_prob)
        st.pyplot(fig_prob)

# --- 4. Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© (Ø£Ø³ÙÙ„ Ø§Ù„ØµÙØ­Ø©) ---
st.divider()
st.subheader("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¹Ø§Ù…Ø©")
tab1, tab2 = st.tabs(["Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª", "Ù…ØµÙÙˆÙØ© Ø§Ù„Ø§Ø±ØªØ¨Ø§Ùƒ"])

with tab1:
    fig_feat, ax_feat = plt.subplots()
    feat_importances.nlargest(10).plot(kind='barh', color='lightgreen', ax=ax_feat)
    st.pyplot(fig_feat)

with tab2:
    y_pred = model.predict(X_test)
    fig_cm, ax_cm = plt.subplots()
    cm = confusion_matrix(y_test, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le.classes_, yticklabels=le.classes_)
    st.pyplot(fig_cm)